import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

# 1. Завантаження датасету
df = pd.read_csv('heart.csv')

# 2. Попередній аналіз та підготовка даних
print("Перші 5 рядків датасету:")
print(df.head())

print("\nІнформація про датасет:")
print(df.info())

print("\nОпис датасету:")
print(df.describe())

print("\nПеревірка на наявність пропущених значень:")
print(df.isnull().sum())

# Візуалізація розподілу цільової змінної
plt.figure(figsize=(6, 4))
sns.countplot(x='DEATH_EVENT', data=df)
plt.title('Розподіл цільової змінної DEATH_EVENT')
plt.show()

# Візуалізація кореляційної матриці
plt.figure(figsize=(12, 8))
corr_matrix = df.corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Матриця кореляцій')
plt.show()

# Розділення даних на ознаки та цільову змінну
X = df.drop('DEATH_EVENT', axis=1)
y = df['DEATH_EVENT']

# Розділення на тренувальний та тестовий набори
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Масштабування даних
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 3. Побудова логістичної регресії з використанням TensorFlow/Keras
model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer=Adam(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

history = model.fit(X_train_scaled, y_train,
                    epochs=100,
                    batch_size=32,
                    validation_split=0.2,
                    callbacks=[early_stopping],
                    verbose=1)

# 4. Графіки функції втрат та точності
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Тренувальні втрати')
plt.plot(history.history['val_loss'], label='Валідаційні втрати')
plt.title('Функція втрат')
plt.xlabel('Епохи')
plt.ylabel('Втрати')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Тренувальна точність')
plt.plot(history.history['val_accuracy'], label='Валідаційна точність')
plt.title('Точність')
plt.xlabel('Епохи')
plt.ylabel('Точність')
plt.legend()

plt.tight_layout()
plt.show()

# Оцінка моделі на тестових даних
y_pred_prob = model.predict(X_test_scaled)
y_pred = (y_pred_prob > 0.5).astype(int)

print("\nМетрики для нейронної мережі (TensorFlow/Keras):")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred))
print("Recall:", recall_score(y_test, y_pred))
print("F1 Score:", f1_score(y_test, y_pred))
print("ROC AUC:", roc_auc_score(y_test, y_pred_prob))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Матриця плутанини
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('Матриця плутанини (нейронна мережа)')
plt.xlabel('Прогнозовані значення')
plt.ylabel('Фактичні значення')
plt.show()

# 5. Підтвердження розрахунків за допомогою класичної логістичної регресії
logreg = LogisticRegression(max_iter=1000, random_state=42)
logreg.fit(X_train_scaled, y_train)

y_pred_logreg = logreg.predict(X_test_scaled)
y_pred_prob_logreg = logreg.predict_proba(X_test_scaled)[:, 1]

print("\nМетрики для класичної логістичної регресії (scikit-learn):")
print("Accuracy:", accuracy_score(y_test, y_pred_logreg))
print("Precision:", precision_score(y_test, y_pred_logreg))
print("Recall:", recall_score(y_test, y_pred_logreg))
print("F1 Score:", f1_score(y_test, y_pred_logreg))
print("ROC AUC:", roc_auc_score(y_test, y_pred_prob_logreg))
print("\nClassification Report:")
print(classification_report(y_test, y_pred_logreg))

# Матриця плутанини для класичної моделі
cm_logreg = confusion_matrix(y_test, y_pred_logreg)
plt.figure(figsize=(6, 4))
sns.heatmap(cm_logreg, annot=True, fmt='d', cmap='Greens', cbar=False)
plt.title('Матриця плутанини (логістична регресія)')
plt.xlabel('Прогнозовані значення')
plt.ylabel('Фактичні значення')
plt.show()

# 6. Порівняння результатів
results = pd.DataFrame({
    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC'],
    'Neural Network': [
        accuracy_score(y_test, y_pred),
        precision_score(y_test, y_pred),
        recall_score(y_test, y_pred),
        f1_score(y_test, y_pred),
        roc_auc_score(y_test, y_pred_prob)
    ],
    'Logistic Regression': [
        accuracy_score(y_test, y_pred_logreg),
        precision_score(y_test, y_pred_logreg),
        recall_score(y_test, y_pred_logreg),
        f1_score(y_test, y_pred_logreg),
        roc_auc_score(y_test, y_pred_prob_logreg)
    ]
})

print("\nПорівняння результатів:")
print(results)

# 7. Висновки
print("\nВисновки:")
print("1. Обидві моделі демонструють подібну ефективність у прогнозуванні смертей пацієнтів.")
print("2. Нейронна мережа показала трохи кращі результати за деякими метриками, але різниця незначна.")
print("3. Класична логістична регресія є простішою моделлю і може бути кращим вибором для цього завдання через свою інтерпретованість.")
print("4. Обидві моделі мають дещо нижчий recall, що вказує на проблеми з виявленням усіх позитивних випадків (смертей).")
print("5. Для покращення результатів можна спробувати:")
print("   - Додаткове налаштування гіперпараметрів моделей")
print("   - Використання інших алгоритмів (наприклад, Random Forest або XGBoost)")
print("   - Збільшення обсягу даних або збалансування класів")
